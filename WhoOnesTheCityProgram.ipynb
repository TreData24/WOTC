{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "382a09b4-00d6-463b-9fb7-d30df9afef2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kbrooks\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model and tokenizer loaded successfully.\n",
      "NER pipeline initialized successfully.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your address or building name:  THE FLATS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities extracted successfully.\n",
      "Building info lookup completed.\n",
      "Result:\n",
      "The building 'The Flats at Dupont Circle Apartments' is located at 2000 N STREET. NW \n",
      "Washington DC 20036 and is owned by Equity Apartments.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import BertTokenizer, BertForTokenClassification, pipeline\n",
    "import torch\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load Excel file\n",
    "file_path = 'E:\\\\Sqool Stupf\\\\DEEP LEARNING\\\\Project\\\\Defendants&DC_Addressess.xlsx'\n",
    "df_units = pd.read_excel(file_path, sheet_name='Address_Points')\n",
    "df_defendants = pd.read_excel(file_path, sheet_name='Defendants')\n",
    "print(\"Excel file loaded successfully.\")\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer for NER\n",
    "tokenizer_ner = BertTokenizer.from_pretrained('dbmdz/bert-large-cased-finetuned-conll03-english')\n",
    "model_ner = BertForTokenClassification.from_pretrained('dbmdz/bert-large-cased-finetuned-conll03-english')\n",
    "print(\"BERT model and tokenizer loaded successfully.\")\n",
    "\n",
    "# Initialize the NER pipeline\n",
    "ner_pipeline = pipeline('ner', model=model_ner, tokenizer=tokenizer_ner, device=device.index)\n",
    "print(\"NER pipeline initialized successfully.\")\n",
    "\n",
    "# Ordinals mapping\n",
    "ORDINAL_MAP = {\n",
    "    '1st': 'first', '2nd': 'second', '3rd': 'third', '4th': 'fourth', '5th': 'fifth',\n",
    "    '6th': 'sixth', '7th': 'seventh', '8th': 'eighth', '9th': 'ninth', '10th': 'tenth',\n",
    "    '11th': 'eleventh', '12th': 'twelfth', '13th': 'thirteenth', '14th': 'fourteenth',\n",
    "    '15th': 'fifteenth', '16th': 'sixteenth', '17th': 'seventeenth', '18th': 'eighteenth',\n",
    "    '19th': 'nineteenth', '20th': 'twentieth', '21st': 'twenty-first', '22nd': 'twenty-second',\n",
    "    '23rd': 'twenty-third', '24th': 'twenty-fourth', '25th': 'twenty-fifth', '26th': 'twenty-sixth',\n",
    "    '27th': 'twenty-seventh', '28th': 'twenty-eighth', '29th': 'twenty-ninth', '30th': 'thirtieth',\n",
    "    '31st': 'thirty-first', '32nd': 'thirty-second', '33rd': 'thirty-third', '34th': 'thirty-fourth',\n",
    "    '35th': 'thirty-fifth', '36th': 'thirty-sixth', '37th': 'thirty-seventh', '38th': 'thirty-eighth',\n",
    "    '39th': 'thirty-ninth', '40th': 'fortieth', '41st': 'forty-first', '42nd': 'forty-second',\n",
    "    '43rd': 'forty-third'\n",
    "}\n",
    "\n",
    "# Function to normalize ordinals in text\n",
    "def normalize_ordinals(text):\n",
    "    for ordinal, word in ORDINAL_MAP.items():\n",
    "        text = re.sub(rf'\\b{ordinal}\\b', word, text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "# Function to clean and standardize text inputs\n",
    "def standardize_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = normalize_ordinals(text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Function to extract named entities using the NER pipeline\n",
    "def extract_entities(text):\n",
    "    entities = ner_pipeline(text)\n",
    "    return entities\n",
    "\n",
    "# Function to check if an address is owned by a defendant\n",
    "def check_address_ownership(partial_address, df_defendants):\n",
    "    standardized_partial_address = standardize_text(partial_address)\n",
    "    \n",
    "    # Search for partial matches in the Defendant Full Address column\n",
    "    matches = df_defendants[df_defendants['Defendant Full Address'].apply(standardize_text).str.contains(standardized_partial_address, na=False)]\n",
    "    \n",
    "    if not matches.empty:\n",
    "        results = []\n",
    "        for _, row in matches.iterrows():\n",
    "            if pd.notna(row['Defendant']):\n",
    "                results.append(f\"{row['Defendant Full Address']} is owned by and/or operated by {row['Defendant']}.\")\n",
    "            else:\n",
    "                results.append(f\"'{partial_address}' is not owned or operated by any known defendant.\")\n",
    "        print(\"Address ownership check completed.\")\n",
    "        return '\\n'.join(results)\n",
    "    else:\n",
    "        print(\"Address ownership check completed: No matches found.\")\n",
    "        return f\"'{partial_address}' is not owned or operated by any known defendant.\"\n",
    "\n",
    "# Function to find the full address and defendant by building name\n",
    "def find_building_info(building_name, df_defendants):\n",
    "    standardized_building_name = standardize_text(building_name)\n",
    "    \n",
    "    # Search for matches in the Building Name column\n",
    "    matches = df_defendants[df_defendants['Building Name'].apply(standardize_text).str.contains(standardized_building_name, na=False)]\n",
    "    \n",
    "    if not matches.empty:\n",
    "        results = []\n",
    "        for _, row in matches.iterrows():\n",
    "            results.append(f\"The building '{row['Building Name']}' is located at {row['Defendant Full Address']} and is owned by {row['Defendant']}.\")\n",
    "        print(\"Building info lookup completed.\")\n",
    "        return '\\n'.join(results)\n",
    "    else:\n",
    "        print(\"Building info lookup completed: No matches found.\")\n",
    "        return f\"'{building_name}' does not match any known building names.\"\n",
    "\n",
    "# Main program logic\n",
    "user_input = input(\"Please enter your address or building name: \")\n",
    "\n",
    "# Extract entities from user input\n",
    "entities = extract_entities(user_input)\n",
    "print(\"Entities extracted successfully.\")\n",
    "\n",
    "# Determine if the input is likely a building name or an address\n",
    "if any(char.isdigit() for char in user_input):\n",
    "    result = check_address_ownership(user_input, df_defendants)\n",
    "else:\n",
    "    result = find_building_info(user_input, df_defendants)\n",
    "\n",
    "# Output the result\n",
    "print(\"Result:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2bfe49-e977-4174-b54c-b0df50495b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
